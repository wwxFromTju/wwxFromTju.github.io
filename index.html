<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- DELETE THIS SCRIPT if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Weixun Wang 王维埙</title>
  
  <meta name="author" content="Weixun Wang 王维埙">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Weixun Wang 王维埙</name>
              </p>
              <p>I’m a PhD student at <a href="http://scs.tju.edu.cn/plus/list.php?tid=3">Tianjin University </a> in Professor <a href="http://www.escience.cn/people/jianye/index.html;jsessionid=A90C80C8698AA0C206F72C6A1945DE44-n2">Jianye Hao</a>’s group, where I work on Multiagent (Deep) Reinforcement Learning.
              </p>
              <p>

              </p>
              <p style="text-align:center">
                <a href="mailto:wxwang@tju.edu.cn">Email</a> &nbsp/&nbsp
<!--                <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp-->
<!--                <a href="data/JonBarron-bio.txt">Biography</a> &nbsp/&nbsp-->
                <a href="https://scholar.google.com.hk/citations?user=pG1-T4QAAAAJ&hl=en">Google Scholar</a>
<!--                <a href="http://www.linkedin.com/in/jonathanbarron/"> LinkedIn </a>-->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/weixunwang.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/weixunwang.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I have an interest in using deep reinforcement learning in multi-agent systems. I believe that MAS (Multi-Agent) is a more realistic description of the (large) problem in the real world. I also believe that deep reinforcement learning can solve more complex practical problems in the MAS field.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td style="padding:20px;width:20%;vertical-align:middle">
              <img src='images/DyMA_CL.png' height="150" width="200">
            </td>
            <td style="padding:25px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1909.02790">
                <papertitle>From Few to More: Large-scale Dynamic Multiagent Curriculum Learning</papertitle>
              </a>
              <br>
              Weixun Wang, Tianpei Yang, Yong Liu, Jianye Hao, Xiaotian Hao, Yujing Hu, Yingfeng Chen, Changjie Fan, Yang Gao
              <br>
              <br> arXiv preprint
              <br>
              <p></p>
              <p> In this paper, we design a novel Dynamic Multiagent Curriculum Learning (DyMA-CL) to solve large-scale problems by starting from learning on a multiagent scenario with a small size and progressively increasing the number of agents. We propose three transfer mechanisms across curricula to accelerate the learning process. Moreover, due to the fact that the state dimension varies across curricula,, and existing network structures cannot be applied in such a transfer setting since their network input sizes are fixed. Therefore, we design a novel network structure called Dynamic Agent-number Network (DyAN) to handle the dynamic size of the network input.
              </p>
            </td>
          </tr>


          <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td style="padding:20px;width:20%;vertical-align:middle">
              <img src='images/ARN.png' height="150" width="200">
            </td>
            <td style="padding:25px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1907.11461">
                <papertitle>Action Semantics Network: Considering the Effects of Actions in Multiagent Systems</papertitle>
              </a>
              <br>
              Weixun Wang, Tianpei Yang Yong Liu, Jianye Hao, Xiaotian Hao, Yujing Hu, Yingfeng Chen, Changjie Fan, Yang Gao
              <br>
              <br> arXiv preprint
              <br>
              <p></p>
              <p>In this paper, we propose a novel network architecture, named Action Semantics Network (ASN), that explicitly represents such action semantics between agents. ASN characterizes different actions' influence on other agents using neural networks based on the action semantics between agents. 
              </p>
            </td>
          </tr>


          <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td style="padding:20px;width:20%;vertical-align:middle">
              <img src='images/L2A.png' height="150" width="200">
            </td>
            <td style="padding:25px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1809.03149">
                <papertitle>Learning Adaptive Display Exposure for Real-Time Advertising</papertitle>
              </a>
              <br>
              Weixun Wang, Junqi Jin, Jianye Hao, Chunjie Chen, Chuan Yu, Weinan Zhang, Jun Wang, Yixi Wang, Han Li, Jian Xu, Kun Gai
              <br>
              <br> CIKM 2019
              <br>
              <p></p>
              <p>In this paper, we investigate the problem of advertising with adaptive exposure, in which the number of ad slots and their locations can dynamically change over time based on their relative scores with recommendation products.
              </p>
            </td>
          </tr>

          <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td style="padding:20px;width:20%;vertical-align:middle">
                <img src='images/GASIL.png' height="150" width="200">
            </td>
            <td style="padding:25px;width:75%;vertical-align:middle">
              <a href="https://dl.acm.org/citation.cfm?id=3331837">
                <papertitle>Independent Generative Adversarial Self-Imitation Learning in Cooperative Multiagent Systems</papertitle>
              </a>
              <br>
              Xiaotian Hao *(Equal contribution),
              <strong>Weixun Wang *(Equal contribution), </strong>
              Jianye Hao,
              Yaodong Yang
              <br>
              <br> AAMAS 2019
              <br>
              <p></p>
              <p>The first to combine self imitation learning with GAIL and propose a novel framework IGASIL to address the multiagent coordination problems.
              </p>
            </td>
          </tr>

          <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td style="padding:18px;width:20%;vertical-align:middle">
              <img src='images/SPD.png' height="170" width="210">
            </td>
            <td style="padding:25px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1803.00162">
                <papertitle>Towards Cooperation in Sequential Prisoner's Dilemmas: a Deep Multiagent Reinforcement Learning Approach</papertitle>
              </a>
              <br>
              Weixun Wang, Jianye Hao, Yixi Wang, Matthew Taylor
              <br>
              <br> AAMAS 2018 Workshop ALA
              <br>
              <p></p>
              <p> In this work, we propose a deep multiagent reinforcement learning approach that investigates the evolution of mutual cooperation in SPD games.
              </p>
            </td>
          </tr>

        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
